{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('tox21/tox21_dense_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "AW            0\n",
       "AWeight       0\n",
       "Arto          0\n",
       "BertzCT       0\n",
       "             ..\n",
       "WPSA1         0\n",
       "WPSA2         0\n",
       "WPSA3         0\n",
       "grav          0\n",
       "rygr          0\n",
       "Length: 802, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)-df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_train=df\n",
    "dense_test=pd.read_csv('tox21/tox21_dense_test.csv')\n",
    "labels_test=pd.read_csv('tox21/tox21_labels_test.csv')\n",
    "labesl_train=pd.read_csv('tox21/tox21_labels_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>AW</th>\n",
       "      <th>AWeight</th>\n",
       "      <th>Arto</th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>Chi0</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi10</th>\n",
       "      <th>Chi2</th>\n",
       "      <th>Chi3</th>\n",
       "      <th>...</th>\n",
       "      <th>W3D</th>\n",
       "      <th>W3DH</th>\n",
       "      <th>WNSA1</th>\n",
       "      <th>WNSA2</th>\n",
       "      <th>WNSA3</th>\n",
       "      <th>WPSA1</th>\n",
       "      <th>WPSA2</th>\n",
       "      <th>WPSA3</th>\n",
       "      <th>grav</th>\n",
       "      <th>rygr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCGC00261900-01</td>\n",
       "      <td>2.612482e+07</td>\n",
       "      <td>12.688</td>\n",
       "      <td>2.226</td>\n",
       "      <td>3.226</td>\n",
       "      <td>37.329</td>\n",
       "      <td>25.440</td>\n",
       "      <td>3.663</td>\n",
       "      <td>24.200</td>\n",
       "      <td>20.222</td>\n",
       "      <td>...</td>\n",
       "      <td>9687.312</td>\n",
       "      <td>42351.907</td>\n",
       "      <td>194.444</td>\n",
       "      <td>-2518.829</td>\n",
       "      <td>-83.110</td>\n",
       "      <td>772.051</td>\n",
       "      <td>10001.075</td>\n",
       "      <td>131.633</td>\n",
       "      <td>145.967</td>\n",
       "      <td>5.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCGC00260869-01</td>\n",
       "      <td>8.333337e+06</td>\n",
       "      <td>17.500</td>\n",
       "      <td>2.167</td>\n",
       "      <td>2.923</td>\n",
       "      <td>16.353</td>\n",
       "      <td>10.872</td>\n",
       "      <td>1.193</td>\n",
       "      <td>11.116</td>\n",
       "      <td>9.279</td>\n",
       "      <td>...</td>\n",
       "      <td>1256.410</td>\n",
       "      <td>2621.885</td>\n",
       "      <td>104.011</td>\n",
       "      <td>-475.829</td>\n",
       "      <td>-33.456</td>\n",
       "      <td>219.411</td>\n",
       "      <td>1003.763</td>\n",
       "      <td>76.703</td>\n",
       "      <td>76.043</td>\n",
       "      <td>3.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCGC00261776-01</td>\n",
       "      <td>4.074000e+00</td>\n",
       "      <td>12.464</td>\n",
       "      <td>2.364</td>\n",
       "      <td>3.043</td>\n",
       "      <td>14.681</td>\n",
       "      <td>10.826</td>\n",
       "      <td>2.149</td>\n",
       "      <td>9.980</td>\n",
       "      <td>9.469</td>\n",
       "      <td>...</td>\n",
       "      <td>1072.430</td>\n",
       "      <td>3152.648</td>\n",
       "      <td>93.486</td>\n",
       "      <td>-341.628</td>\n",
       "      <td>-21.327</td>\n",
       "      <td>174.791</td>\n",
       "      <td>638.757</td>\n",
       "      <td>32.885</td>\n",
       "      <td>45.933</td>\n",
       "      <td>3.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCGC00261380-01</td>\n",
       "      <td>8.000005e+06</td>\n",
       "      <td>13.827</td>\n",
       "      <td>2.080</td>\n",
       "      <td>2.845</td>\n",
       "      <td>16.778</td>\n",
       "      <td>11.720</td>\n",
       "      <td>0.777</td>\n",
       "      <td>10.139</td>\n",
       "      <td>8.207</td>\n",
       "      <td>...</td>\n",
       "      <td>1408.177</td>\n",
       "      <td>4596.402</td>\n",
       "      <td>127.215</td>\n",
       "      <td>-519.799</td>\n",
       "      <td>-27.729</td>\n",
       "      <td>199.061</td>\n",
       "      <td>813.323</td>\n",
       "      <td>35.712</td>\n",
       "      <td>58.214</td>\n",
       "      <td>3.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCGC00261842-01</td>\n",
       "      <td>4.838000e+00</td>\n",
       "      <td>14.509</td>\n",
       "      <td>2.087</td>\n",
       "      <td>2.880</td>\n",
       "      <td>16.872</td>\n",
       "      <td>10.920</td>\n",
       "      <td>0.413</td>\n",
       "      <td>10.035</td>\n",
       "      <td>7.719</td>\n",
       "      <td>...</td>\n",
       "      <td>1217.075</td>\n",
       "      <td>4343.460</td>\n",
       "      <td>134.802</td>\n",
       "      <td>-816.522</td>\n",
       "      <td>-55.496</td>\n",
       "      <td>192.858</td>\n",
       "      <td>1168.142</td>\n",
       "      <td>33.190</td>\n",
       "      <td>57.065</td>\n",
       "      <td>3.635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 802 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0            AW  AWeight   Arto  BertzCT    Chi0    Chi1  \\\n",
       "0  NCGC00261900-01  2.612482e+07   12.688  2.226    3.226  37.329  25.440   \n",
       "1  NCGC00260869-01  8.333337e+06   17.500  2.167    2.923  16.353  10.872   \n",
       "2  NCGC00261776-01  4.074000e+00   12.464  2.364    3.043  14.681  10.826   \n",
       "3  NCGC00261380-01  8.000005e+06   13.827  2.080    2.845  16.778  11.720   \n",
       "4  NCGC00261842-01  4.838000e+00   14.509  2.087    2.880  16.872  10.920   \n",
       "\n",
       "   Chi10    Chi2    Chi3  ...       W3D       W3DH    WNSA1     WNSA2   WNSA3  \\\n",
       "0  3.663  24.200  20.222  ...  9687.312  42351.907  194.444 -2518.829 -83.110   \n",
       "1  1.193  11.116   9.279  ...  1256.410   2621.885  104.011  -475.829 -33.456   \n",
       "2  2.149   9.980   9.469  ...  1072.430   3152.648   93.486  -341.628 -21.327   \n",
       "3  0.777  10.139   8.207  ...  1408.177   4596.402  127.215  -519.799 -27.729   \n",
       "4  0.413  10.035   7.719  ...  1217.075   4343.460  134.802  -816.522 -55.496   \n",
       "\n",
       "     WPSA1      WPSA2    WPSA3     grav   rygr  \n",
       "0  772.051  10001.075  131.633  145.967  5.499  \n",
       "1  219.411   1003.763   76.703   76.043  3.728  \n",
       "2  174.791    638.757   32.885   45.933  3.657  \n",
       "3  199.061    813.323   35.712   58.214  3.659  \n",
       "4  192.858   1168.142   33.190   57.065  3.635  \n",
       "\n",
       "[5 rows x 802 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>NR.AhR</th>\n",
       "      <th>NR.AR</th>\n",
       "      <th>NR.AR.LBD</th>\n",
       "      <th>NR.Aromatase</th>\n",
       "      <th>NR.ER</th>\n",
       "      <th>NR.ER.LBD</th>\n",
       "      <th>NR.PPAR.gamma</th>\n",
       "      <th>SR.ARE</th>\n",
       "      <th>SR.ATAD5</th>\n",
       "      <th>SR.HSE</th>\n",
       "      <th>SR.MMP</th>\n",
       "      <th>SR.p53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCGC00261900-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCGC00260869-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCGC00261776-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCGC00261380-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCGC00261842-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  NR.AhR  NR.AR  NR.AR.LBD  NR.Aromatase  NR.ER  NR.ER.LBD  \\\n",
       "0  NCGC00261900-01     0.0    1.0        NaN           0.0    0.0        0.0   \n",
       "1  NCGC00260869-01     0.0    1.0        NaN           NaN    0.0        0.0   \n",
       "2  NCGC00261776-01     1.0    1.0        0.0           NaN    1.0        0.0   \n",
       "3  NCGC00261380-01     NaN    0.0        NaN           1.0    0.0        NaN   \n",
       "4  NCGC00261842-01     0.0    0.0        0.0           NaN    0.0        0.0   \n",
       "\n",
       "   NR.PPAR.gamma  SR.ARE  SR.ATAD5  SR.HSE  SR.MMP  SR.p53  \n",
       "0            0.0     NaN       0.0     0.0     NaN     0.0  \n",
       "1            0.0     0.0       0.0     0.0     0.0     0.0  \n",
       "2            0.0     1.0       1.0     0.0     1.0     0.0  \n",
       "3            NaN     1.0       0.0     NaN     0.0     NaN  \n",
       "4            0.0     0.0       0.0     0.0     NaN     1.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "    Dense(128, input_shape=(801,),activation='relu'),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train=labesl_train\n",
    "labels_train_short=labels_train[['NR.AhR','NR.AR']]\n",
    "labels_test_short=labels_test[['NR.AhR','NR.AR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_train_short=dense_train.copy()\n",
    "for x in range(len(labels_train_short)):\n",
    "    if labels_train_short.iloc[x].isna().sum()>0:\n",
    "        dense_train_short.drop(x,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>AW</th>\n",
       "      <th>AWeight</th>\n",
       "      <th>Arto</th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>Chi0</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi10</th>\n",
       "      <th>Chi2</th>\n",
       "      <th>Chi3</th>\n",
       "      <th>...</th>\n",
       "      <th>W3D</th>\n",
       "      <th>W3DH</th>\n",
       "      <th>WNSA1</th>\n",
       "      <th>WNSA2</th>\n",
       "      <th>WNSA3</th>\n",
       "      <th>WPSA1</th>\n",
       "      <th>WPSA2</th>\n",
       "      <th>WPSA3</th>\n",
       "      <th>grav</th>\n",
       "      <th>rygr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>NCGC00255644-01</td>\n",
       "      <td>2.800000e+07</td>\n",
       "      <td>12.410</td>\n",
       "      <td>2.080</td>\n",
       "      <td>2.793</td>\n",
       "      <td>18.828</td>\n",
       "      <td>11.637</td>\n",
       "      <td>0.949</td>\n",
       "      <td>11.413</td>\n",
       "      <td>8.547</td>\n",
       "      <td>...</td>\n",
       "      <td>1449.070</td>\n",
       "      <td>9509.495</td>\n",
       "      <td>79.822</td>\n",
       "      <td>-506.873</td>\n",
       "      <td>-33.761</td>\n",
       "      <td>330.435</td>\n",
       "      <td>2098.264</td>\n",
       "      <td>52.556</td>\n",
       "      <td>53.351</td>\n",
       "      <td>3.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>NCGC00181002-01</td>\n",
       "      <td>7.407413e+06</td>\n",
       "      <td>13.729</td>\n",
       "      <td>2.074</td>\n",
       "      <td>2.940</td>\n",
       "      <td>18.571</td>\n",
       "      <td>12.449</td>\n",
       "      <td>0.739</td>\n",
       "      <td>11.660</td>\n",
       "      <td>8.890</td>\n",
       "      <td>...</td>\n",
       "      <td>1843.064</td>\n",
       "      <td>6574.474</td>\n",
       "      <td>161.819</td>\n",
       "      <td>-649.313</td>\n",
       "      <td>-29.915</td>\n",
       "      <td>229.543</td>\n",
       "      <td>921.064</td>\n",
       "      <td>33.080</td>\n",
       "      <td>62.124</td>\n",
       "      <td>4.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>NCGC00167436-01</td>\n",
       "      <td>7.249000e+00</td>\n",
       "      <td>12.753</td>\n",
       "      <td>2.186</td>\n",
       "      <td>3.187</td>\n",
       "      <td>30.673</td>\n",
       "      <td>20.634</td>\n",
       "      <td>2.092</td>\n",
       "      <td>19.144</td>\n",
       "      <td>15.256</td>\n",
       "      <td>...</td>\n",
       "      <td>5234.536</td>\n",
       "      <td>18283.847</td>\n",
       "      <td>209.403</td>\n",
       "      <td>-1902.070</td>\n",
       "      <td>-66.263</td>\n",
       "      <td>457.218</td>\n",
       "      <td>4152.910</td>\n",
       "      <td>80.147</td>\n",
       "      <td>115.139</td>\n",
       "      <td>4.469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>NCGC00254013-01</td>\n",
       "      <td>4.761912e+06</td>\n",
       "      <td>14.160</td>\n",
       "      <td>2.143</td>\n",
       "      <td>3.085</td>\n",
       "      <td>29.037</td>\n",
       "      <td>19.738</td>\n",
       "      <td>2.031</td>\n",
       "      <td>18.023</td>\n",
       "      <td>15.931</td>\n",
       "      <td>...</td>\n",
       "      <td>4665.508</td>\n",
       "      <td>21499.264</td>\n",
       "      <td>158.956</td>\n",
       "      <td>-1336.297</td>\n",
       "      <td>-32.575</td>\n",
       "      <td>405.901</td>\n",
       "      <td>3412.082</td>\n",
       "      <td>62.946</td>\n",
       "      <td>135.627</td>\n",
       "      <td>4.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>NCGC00254071-01</td>\n",
       "      <td>4.444452e+06</td>\n",
       "      <td>14.296</td>\n",
       "      <td>2.133</td>\n",
       "      <td>3.215</td>\n",
       "      <td>31.380</td>\n",
       "      <td>21.105</td>\n",
       "      <td>2.472</td>\n",
       "      <td>19.599</td>\n",
       "      <td>15.781</td>\n",
       "      <td>...</td>\n",
       "      <td>6601.916</td>\n",
       "      <td>22793.661</td>\n",
       "      <td>288.781</td>\n",
       "      <td>-2685.460</td>\n",
       "      <td>-75.005</td>\n",
       "      <td>531.894</td>\n",
       "      <td>4946.241</td>\n",
       "      <td>95.471</td>\n",
       "      <td>130.496</td>\n",
       "      <td>5.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12055</th>\n",
       "      <td>NCGC00261292-01</td>\n",
       "      <td>1.428572e+07</td>\n",
       "      <td>14.255</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.628</td>\n",
       "      <td>9.259</td>\n",
       "      <td>6.309</td>\n",
       "      <td>0.157</td>\n",
       "      <td>5.468</td>\n",
       "      <td>4.484</td>\n",
       "      <td>...</td>\n",
       "      <td>306.364</td>\n",
       "      <td>1435.590</td>\n",
       "      <td>76.419</td>\n",
       "      <td>-190.192</td>\n",
       "      <td>-13.757</td>\n",
       "      <td>100.624</td>\n",
       "      <td>250.402</td>\n",
       "      <td>19.275</td>\n",
       "      <td>29.148</td>\n",
       "      <td>2.581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12056</th>\n",
       "      <td>NCGC00261245-01</td>\n",
       "      <td>1.193182e+07</td>\n",
       "      <td>13.674</td>\n",
       "      <td>2.061</td>\n",
       "      <td>2.920</td>\n",
       "      <td>21.142</td>\n",
       "      <td>15.382</td>\n",
       "      <td>1.201</td>\n",
       "      <td>12.713</td>\n",
       "      <td>10.576</td>\n",
       "      <td>...</td>\n",
       "      <td>2528.642</td>\n",
       "      <td>12293.627</td>\n",
       "      <td>94.878</td>\n",
       "      <td>-595.491</td>\n",
       "      <td>-22.275</td>\n",
       "      <td>324.131</td>\n",
       "      <td>2034.439</td>\n",
       "      <td>49.446</td>\n",
       "      <td>93.636</td>\n",
       "      <td>3.666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12057</th>\n",
       "      <td>NCGC00260828-01</td>\n",
       "      <td>1.081800e+01</td>\n",
       "      <td>12.374</td>\n",
       "      <td>2.045</td>\n",
       "      <td>3.128</td>\n",
       "      <td>33.242</td>\n",
       "      <td>20.457</td>\n",
       "      <td>0.806</td>\n",
       "      <td>19.711</td>\n",
       "      <td>14.799</td>\n",
       "      <td>...</td>\n",
       "      <td>9171.300</td>\n",
       "      <td>44070.070</td>\n",
       "      <td>267.400</td>\n",
       "      <td>-2656.568</td>\n",
       "      <td>-104.039</td>\n",
       "      <td>874.679</td>\n",
       "      <td>8689.849</td>\n",
       "      <td>144.294</td>\n",
       "      <td>91.670</td>\n",
       "      <td>8.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12058</th>\n",
       "      <td>NCGC00260687-01</td>\n",
       "      <td>3.229000e+00</td>\n",
       "      <td>12.543</td>\n",
       "      <td>2.267</td>\n",
       "      <td>2.700</td>\n",
       "      <td>10.251</td>\n",
       "      <td>7.381</td>\n",
       "      <td>0.587</td>\n",
       "      <td>6.455</td>\n",
       "      <td>5.857</td>\n",
       "      <td>...</td>\n",
       "      <td>391.790</td>\n",
       "      <td>1815.417</td>\n",
       "      <td>39.578</td>\n",
       "      <td>-105.234</td>\n",
       "      <td>-9.967</td>\n",
       "      <td>146.565</td>\n",
       "      <td>389.732</td>\n",
       "      <td>23.879</td>\n",
       "      <td>28.201</td>\n",
       "      <td>2.954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12059</th>\n",
       "      <td>NCGC00261465-01</td>\n",
       "      <td>1.931035e+07</td>\n",
       "      <td>15.004</td>\n",
       "      <td>1.867</td>\n",
       "      <td>2.985</td>\n",
       "      <td>20.190</td>\n",
       "      <td>12.619</td>\n",
       "      <td>0.738</td>\n",
       "      <td>12.270</td>\n",
       "      <td>8.882</td>\n",
       "      <td>...</td>\n",
       "      <td>2271.224</td>\n",
       "      <td>4492.115</td>\n",
       "      <td>156.459</td>\n",
       "      <td>-946.731</td>\n",
       "      <td>-68.221</td>\n",
       "      <td>240.955</td>\n",
       "      <td>1458.016</td>\n",
       "      <td>104.638</td>\n",
       "      <td>87.731</td>\n",
       "      <td>4.052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8281 rows × 802 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0            AW  AWeight   Arto  BertzCT    Chi0    Chi1  \\\n",
       "475    NCGC00255644-01  2.800000e+07   12.410  2.080    2.793  18.828  11.637   \n",
       "479    NCGC00181002-01  7.407413e+06   13.729  2.074    2.940  18.571  12.449   \n",
       "486    NCGC00167436-01  7.249000e+00   12.753  2.186    3.187  30.673  20.634   \n",
       "492    NCGC00254013-01  4.761912e+06   14.160  2.143    3.085  29.037  19.738   \n",
       "510    NCGC00254071-01  4.444452e+06   14.296  2.133    3.215  31.380  21.105   \n",
       "...                ...           ...      ...    ...      ...     ...     ...   \n",
       "12055  NCGC00261292-01  1.428572e+07   14.255  2.000    2.628   9.259   6.309   \n",
       "12056  NCGC00261245-01  1.193182e+07   13.674  2.061    2.920  21.142  15.382   \n",
       "12057  NCGC00260828-01  1.081800e+01   12.374  2.045    3.128  33.242  20.457   \n",
       "12058  NCGC00260687-01  3.229000e+00   12.543  2.267    2.700  10.251   7.381   \n",
       "12059  NCGC00261465-01  1.931035e+07   15.004  1.867    2.985  20.190  12.619   \n",
       "\n",
       "       Chi10    Chi2    Chi3  ...       W3D       W3DH    WNSA1     WNSA2  \\\n",
       "475    0.949  11.413   8.547  ...  1449.070   9509.495   79.822  -506.873   \n",
       "479    0.739  11.660   8.890  ...  1843.064   6574.474  161.819  -649.313   \n",
       "486    2.092  19.144  15.256  ...  5234.536  18283.847  209.403 -1902.070   \n",
       "492    2.031  18.023  15.931  ...  4665.508  21499.264  158.956 -1336.297   \n",
       "510    2.472  19.599  15.781  ...  6601.916  22793.661  288.781 -2685.460   \n",
       "...      ...     ...     ...  ...       ...        ...      ...       ...   \n",
       "12055  0.157   5.468   4.484  ...   306.364   1435.590   76.419  -190.192   \n",
       "12056  1.201  12.713  10.576  ...  2528.642  12293.627   94.878  -595.491   \n",
       "12057  0.806  19.711  14.799  ...  9171.300  44070.070  267.400 -2656.568   \n",
       "12058  0.587   6.455   5.857  ...   391.790   1815.417   39.578  -105.234   \n",
       "12059  0.738  12.270   8.882  ...  2271.224   4492.115  156.459  -946.731   \n",
       "\n",
       "         WNSA3    WPSA1     WPSA2    WPSA3     grav   rygr  \n",
       "475    -33.761  330.435  2098.264   52.556   53.351  3.759  \n",
       "479    -29.915  229.543   921.064   33.080   62.124  4.018  \n",
       "486    -66.263  457.218  4152.910   80.147  115.139  4.469  \n",
       "492    -32.575  405.901  3412.082   62.946  135.627  4.192  \n",
       "510    -75.005  531.894  4946.241   95.471  130.496  5.434  \n",
       "...        ...      ...       ...      ...      ...    ...  \n",
       "12055  -13.757  100.624   250.402   19.275   29.148  2.581  \n",
       "12056  -22.275  324.131  2034.439   49.446   93.636  3.666  \n",
       "12057 -104.039  874.679  8689.849  144.294   91.670  8.054  \n",
       "12058   -9.967  146.565   389.732   23.879   28.201  2.954  \n",
       "12059  -68.221  240.955  1458.016  104.638   87.731  4.052  \n",
       "\n",
       "[8281 rows x 802 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_train_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train_short=labels_train_short.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NR.AhR</th>\n",
       "      <th>NR.AR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12055</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12056</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12057</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12058</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12059</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8281 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NR.AhR  NR.AR\n",
       "475       0.0    0.0\n",
       "479       0.0    0.0\n",
       "486       0.0    0.0\n",
       "492       0.0    0.0\n",
       "510       0.0    0.0\n",
       "...       ...    ...\n",
       "12055     0.0    0.0\n",
       "12056     0.0    0.0\n",
       "12057     0.0    0.0\n",
       "12058     0.0    0.0\n",
       "12059     0.0    0.0\n",
       "\n",
       "[8281 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_train_short=dense_train_short.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8281 samples\n",
      "Epoch 1/5\n",
      "8281/8281 [==============================] - 11s 1ms/sample - loss: nan - accuracy: 0.9673\n",
      "Epoch 2/5\n",
      "8281/8281 [==============================] - 1s 151us/sample - loss: nan - accuracy: 0.9673\n",
      "Epoch 3/5\n",
      "8281/8281 [==============================] - 1s 151us/sample - loss: nan - accuracy: 0.9673\n",
      "Epoch 4/5\n",
      "8281/8281 [==============================] - 1s 146us/sample - loss: nan - accuracy: 0.9673\n",
      "Epoch 5/5\n",
      "8281/8281 [==============================] - 1s 179us/sample - loss: nan - accuracy: 0.9673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb3f3b8cc0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dense_train_short.to_numpy(),labels_train_short.to_numpy(),epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.80000028e+07, 1.24100000e+01, 2.08000000e+00, ...,\n",
       "        5.25560000e+01, 5.33510000e+01, 3.75900000e+00],\n",
       "       [7.40741299e+06, 1.37290000e+01, 2.07400000e+00, ...,\n",
       "        3.30800000e+01, 6.21240000e+01, 4.01800000e+00],\n",
       "       [7.24900000e+00, 1.27530000e+01, 2.18600000e+00, ...,\n",
       "        8.01470000e+01, 1.15139000e+02, 4.46900000e+00],\n",
       "       ...,\n",
       "       [1.08180000e+01, 1.23740000e+01, 2.04500000e+00, ...,\n",
       "        1.44294000e+02, 9.16700000e+01, 8.05400000e+00],\n",
       "       [3.22900000e+00, 1.25430000e+01, 2.26700000e+00, ...,\n",
       "        2.38790000e+01, 2.82010000e+01, 2.95400000e+00],\n",
       "       [1.93103494e+07, 1.50040000e+01, 1.86700000e+00, ...,\n",
       "        1.04638000e+02, 8.77310000e+01, 4.05200000e+00]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_train_short.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       ...,\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train_short.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7452/7452 [==============================] - 3s 388us/step - loss: 0.2847 - accuracy: 0.8968\n",
      "Epoch 2/10\n",
      "7452/7452 [==============================] - 3s 345us/step - loss: 0.2305 - accuracy: 0.9087\n",
      "Epoch 3/10\n",
      "7452/7452 [==============================] - 3s 355us/step - loss: 0.2084 - accuracy: 0.9204\n",
      "Epoch 4/10\n",
      "7452/7452 [==============================] - 3s 347us/step - loss: 0.1911 - accuracy: 0.9257\n",
      "Epoch 5/10\n",
      "7452/7452 [==============================] - 3s 344us/step - loss: 0.1765 - accuracy: 0.9300\n",
      "Epoch 6/10\n",
      "7452/7452 [==============================] - 3s 382us/step - loss: 0.1599 - accuracy: 0.9364\n",
      "Epoch 7/10\n",
      "7452/7452 [==============================] - 3s 402us/step - loss: 0.1496 - accuracy: 0.9414\n",
      "Epoch 8/10\n",
      "7452/7452 [==============================] - 3s 359us/step - loss: 0.1386 - accuracy: 0.9450\n",
      "Epoch 9/10\n",
      "7452/7452 [==============================] - 3s 358us/step - loss: 0.1243 - accuracy: 0.9542\n",
      "Epoch 10/10\n",
      "7452/7452 [==============================] - 3s 369us/step - loss: 0.1141 - accuracy: 0.9565\n",
      "829/829 [==============================] - 0s 297us/step\n",
      "Epoch 1/10\n",
      "7453/7453 [==============================] - 3s 402us/step - loss: 0.2894 - accuracy: 0.8940\n",
      "Epoch 2/10\n",
      "7453/7453 [==============================] - 2s 321us/step - loss: 0.2333 - accuracy: 0.9096\n",
      "Epoch 3/10\n",
      "7453/7453 [==============================] - 3s 347us/step - loss: 0.2178 - accuracy: 0.91490s - loss: 0.2199 - accuracy: 0.\n",
      "Epoch 4/10\n",
      "7453/7453 [==============================] - 2s 310us/step - loss: 0.1993 - accuracy: 0.9226\n",
      "Epoch 5/10\n",
      "7453/7453 [==============================] - 2s 320us/step - loss: 0.1941 - accuracy: 0.9289\n",
      "Epoch 6/10\n",
      "7453/7453 [==============================] - 2s 302us/step - loss: 0.1666 - accuracy: 0.9339\n",
      "Epoch 7/10\n",
      "7453/7453 [==============================] - 2s 313us/step - loss: 0.1545 - accuracy: 0.9361\n",
      "Epoch 8/10\n",
      "7453/7453 [==============================] - 2s 325us/step - loss: 0.1383 - accuracy: 0.9466\n",
      "Epoch 9/10\n",
      "7453/7453 [==============================] - 2s 330us/step - loss: 0.1246 - accuracy: 0.9504\n",
      "Epoch 10/10\n",
      "7453/7453 [==============================] - 3s 346us/step - loss: 0.1142 - accuracy: 0.9560\n",
      "828/828 [==============================] - 0s 201us/step\n",
      "Epoch 1/10\n",
      "7453/7453 [==============================] - 3s 370us/step - loss: 0.2905 - accuracy: 0.8925\n",
      "Epoch 2/10\n",
      "7453/7453 [==============================] - 3s 339us/step - loss: 0.2341 - accuracy: 0.9109\n",
      "Epoch 3/10\n",
      "7453/7453 [==============================] - 3s 389us/step - loss: 0.2184 - accuracy: 0.9152\n",
      "Epoch 4/10\n",
      "7453/7453 [==============================] - 3s 351us/step - loss: 0.2041 - accuracy: 0.9230\n",
      "Epoch 5/10\n",
      "7453/7453 [==============================] - 3s 350us/step - loss: 0.1785 - accuracy: 0.9310\n",
      "Epoch 6/10\n",
      "7453/7453 [==============================] - 3s 370us/step - loss: 0.1657 - accuracy: 0.9356\n",
      "Epoch 7/10\n",
      "7453/7453 [==============================] - 3s 396us/step - loss: 0.1489 - accuracy: 0.9398\n",
      "Epoch 8/10\n",
      "7453/7453 [==============================] - 4s 471us/step - loss: 0.1352 - accuracy: 0.9502\n",
      "Epoch 9/10\n",
      "7453/7453 [==============================] - 3s 453us/step - loss: 0.1217 - accuracy: 0.9520\n",
      "Epoch 10/10\n",
      "7453/7453 [==============================] - 5s 637us/step - loss: 0.1155 - accuracy: 0.9588\n",
      "828/828 [==============================] - 5s 6ms/step\n",
      "Epoch 1/10\n",
      "7453/7453 [==============================] - 4s 566us/step - loss: 0.2832 - accuracy: 0.8968\n",
      "Epoch 2/10\n",
      "7453/7453 [==============================] - 3s 400us/step - loss: 0.2324 - accuracy: 0.9088\n",
      "Epoch 3/10\n",
      "7453/7453 [==============================] - 3s 381us/step - loss: 0.2106 - accuracy: 0.9208\n",
      "Epoch 4/10\n",
      "7453/7453 [==============================] - 3s 339us/step - loss: 0.1889 - accuracy: 0.9284\n",
      "Epoch 5/10\n",
      "7453/7453 [==============================] - 3s 336us/step - loss: 0.1819 - accuracy: 0.9301\n",
      "Epoch 6/10\n",
      "7453/7453 [==============================] - 3s 338us/step - loss: 0.1613 - accuracy: 0.9383\n",
      "Epoch 7/10\n",
      "7453/7453 [==============================] - 3s 349us/step - loss: 0.1505 - accuracy: 0.9412\n",
      "Epoch 8/10\n",
      "7453/7453 [==============================] - 3s 344us/step - loss: 0.1397 - accuracy: 0.9463\n",
      "Epoch 9/10\n",
      "7453/7453 [==============================] - 3s 443us/step - loss: 0.1205 - accuracy: 0.9551\n",
      "Epoch 10/10\n",
      "7453/7453 [==============================] - 4s 535us/step - loss: 0.1113 - accuracy: 0.9553\n",
      "828/828 [==============================] - 0s 256us/step\n",
      "Epoch 1/10\n",
      "7453/7453 [==============================] - 3s 414us/step - loss: 0.2801 - accuracy: 0.8960\n",
      "Epoch 2/10\n",
      "7453/7453 [==============================] - 3s 357us/step - loss: 0.2283 - accuracy: 0.9128\n",
      "Epoch 3/10\n",
      "7453/7453 [==============================] - 3s 372us/step - loss: 0.2136 - accuracy: 0.9192\n",
      "Epoch 4/10\n",
      "7453/7453 [==============================] - 3s 341us/step - loss: 0.1982 - accuracy: 0.9237\n",
      "Epoch 5/10\n",
      "7453/7453 [==============================] - 3s 400us/step - loss: 0.1821 - accuracy: 0.93120s - loss:\n",
      "Epoch 6/10\n",
      "7453/7453 [==============================] - 4s 486us/step - loss: 0.1650 - accuracy: 0.9341\n",
      "Epoch 7/10\n",
      "7453/7453 [==============================] - 3s 382us/step - loss: 0.1619 - accuracy: 0.9387\n",
      "Epoch 8/10\n",
      "7453/7453 [==============================] - 3s 371us/step - loss: 0.1396 - accuracy: 0.9458\n",
      "Epoch 9/10\n",
      "7453/7453 [==============================] - 3s 370us/step - loss: 0.1325 - accuracy: 0.9487\n",
      "Epoch 10/10\n",
      "7453/7453 [==============================] - 3s 338us/step - loss: 0.1125 - accuracy: 0.9553\n",
      "828/828 [==============================] - 0s 225us/step\n",
      "Epoch 1/10\n",
      "7453/7453 [==============================] - 3s 377us/step - loss: 0.2766 - accuracy: 0.8961\n",
      "Epoch 2/10\n",
      "7453/7453 [==============================] - 3s 352us/step - loss: 0.2334 - accuracy: 0.9110\n",
      "Epoch 3/10\n",
      "7453/7453 [==============================] - 3s 371us/step - loss: 0.2051 - accuracy: 0.9206\n",
      "Epoch 4/10\n",
      "7453/7453 [==============================] - 3s 353us/step - loss: 0.1896 - accuracy: 0.9258\n",
      "Epoch 5/10\n",
      "7453/7453 [==============================] - 3s 341us/step - loss: 0.1752 - accuracy: 0.9324\n",
      "Epoch 6/10\n",
      "7453/7453 [==============================] - 3s 336us/step - loss: 0.1575 - accuracy: 0.9379\n",
      "Epoch 7/10\n",
      "7453/7453 [==============================] - 3s 342us/step - loss: 0.1422 - accuracy: 0.9447\n",
      "Epoch 8/10\n",
      "7453/7453 [==============================] - 3s 349us/step - loss: 0.1264 - accuracy: 0.9494\n",
      "Epoch 9/10\n",
      "7453/7453 [==============================] - 2s 329us/step - loss: 0.1143 - accuracy: 0.9555\n",
      "Epoch 10/10\n",
      "7453/7453 [==============================] - 3s 353us/step - loss: 0.1005 - accuracy: 0.9630\n",
      "828/828 [==============================] - 0s 202us/step\n",
      "Epoch 1/10\n",
      "7453/7453 [==============================] - 3s 447us/step - loss: 0.2810 - accuracy: 0.8952\n",
      "Epoch 2/10\n",
      "7453/7453 [==============================] - 3s 380us/step - loss: 0.2361 - accuracy: 0.9108\n",
      "Epoch 3/10\n",
      "7453/7453 [==============================] - 3s 352us/step - loss: 0.2138 - accuracy: 0.9178\n",
      "Epoch 4/10\n",
      "7453/7453 [==============================] - 3s 341us/step - loss: 0.1980 - accuracy: 0.9233\n",
      "Epoch 5/10\n",
      "7453/7453 [==============================] - 3s 337us/step - loss: 0.1855 - accuracy: 0.9254\n",
      "Epoch 6/10\n",
      "7453/7453 [==============================] - 3s 345us/step - loss: 0.1682 - accuracy: 0.9356\n",
      "Epoch 7/10\n",
      "7453/7453 [==============================] - 3s 341us/step - loss: 0.1533 - accuracy: 0.9416\n",
      "Epoch 8/10\n",
      "7453/7453 [==============================] - 3s 369us/step - loss: 0.1375 - accuracy: 0.9471\n",
      "Epoch 9/10\n",
      "7453/7453 [==============================] - 4s 499us/step - loss: 0.1325 - accuracy: 0.9501\n",
      "Epoch 10/10\n",
      "7453/7453 [==============================] - 4s 494us/step - loss: 0.1194 - accuracy: 0.9546\n",
      "828/828 [==============================] - 0s 273us/step\n",
      "Epoch 1/10\n",
      "7453/7453 [==============================] - 4s 514us/step - loss: 0.2809 - accuracy: 0.8949\n",
      "Epoch 2/10\n",
      "7453/7453 [==============================] - 4s 504us/step - loss: 0.2341 - accuracy: 0.9096\n",
      "Epoch 3/10\n",
      "7453/7453 [==============================] - 3s 357us/step - loss: 0.2093 - accuracy: 0.9200\n",
      "Epoch 4/10\n",
      "7453/7453 [==============================] - 3s 340us/step - loss: 0.1944 - accuracy: 0.9245\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7453/7453 [==============================] - 3s 340us/step - loss: 0.1766 - accuracy: 0.9308\n",
      "Epoch 6/10\n",
      "7453/7453 [==============================] - 3s 350us/step - loss: 0.1606 - accuracy: 0.9367\n",
      "Epoch 7/10\n",
      "7453/7453 [==============================] - 3s 355us/step - loss: 0.1556 - accuracy: 0.9414\n",
      "Epoch 8/10\n",
      "7453/7453 [==============================] - 3s 353us/step - loss: 0.1349 - accuracy: 0.9474\n",
      "Epoch 9/10\n",
      "7453/7453 [==============================] - 4s 548us/step - loss: 0.1189 - accuracy: 0.9530\n",
      "Epoch 10/10\n",
      "7453/7453 [==============================] - 4s 481us/step - loss: 0.1154 - accuracy: 0.9548\n",
      "828/828 [==============================] - 0s 326us/step\n",
      "Epoch 1/10\n",
      "7453/7453 [==============================] - 4s 485us/step - loss: 0.2907 - accuracy: 0.8920\n",
      "Epoch 2/10\n",
      "7453/7453 [==============================] - 3s 406us/step - loss: 0.2333 - accuracy: 0.9067\n",
      "Epoch 3/10\n",
      "7453/7453 [==============================] - 3s 418us/step - loss: 0.2140 - accuracy: 0.9131\n",
      "Epoch 4/10\n",
      "7453/7453 [==============================] - 3s 434us/step - loss: 0.1940 - accuracy: 0.9241\n",
      "Epoch 5/10\n",
      "7453/7453 [==============================] - 3s 419us/step - loss: 0.1804 - accuracy: 0.9279\n",
      "Epoch 6/10\n",
      "7453/7453 [==============================] - 3s 423us/step - loss: 0.1607 - accuracy: 0.9377\n",
      "Epoch 7/10\n",
      "7453/7453 [==============================] - 3s 419us/step - loss: 0.1458 - accuracy: 0.9440\n",
      "Epoch 8/10\n",
      "7453/7453 [==============================] - 3s 459us/step - loss: 0.1364 - accuracy: 0.9447\n",
      "Epoch 9/10\n",
      "7453/7453 [==============================] - 3s 426us/step - loss: 0.1251 - accuracy: 0.9521\n",
      "Epoch 10/10\n",
      "7453/7453 [==============================] - 3s 432us/step - loss: 0.1127 - accuracy: 0.9569\n",
      "828/828 [==============================] - 0s 281us/step\n",
      "Epoch 1/10\n",
      "7453/7453 [==============================] - 5s 630us/step - loss: 0.2962 - accuracy: 0.89020s - loss: 0.3011 - accura\n",
      "Epoch 2/10\n",
      "7453/7453 [==============================] - 4s 498us/step - loss: 0.2428 - accuracy: 0.9067\n",
      "Epoch 3/10\n",
      "7453/7453 [==============================] - 4s 572us/step - loss: 0.2145 - accuracy: 0.9149\n",
      "Epoch 4/10\n",
      "7453/7453 [==============================] - 4s 555us/step - loss: 0.1934 - accuracy: 0.9235\n",
      "Epoch 5/10\n",
      "7453/7453 [==============================] - 4s 491us/step - loss: 0.1782 - accuracy: 0.9286\n",
      "Epoch 6/10\n",
      "7453/7453 [==============================] - 3s 435us/step - loss: 0.1627 - accuracy: 0.9353\n",
      "Epoch 7/10\n",
      "7453/7453 [==============================] - 4s 470us/step - loss: 0.1543 - accuracy: 0.9418\n",
      "Epoch 8/10\n",
      "7453/7453 [==============================] - 3s 420us/step - loss: 0.1386 - accuracy: 0.9481\n",
      "Epoch 9/10\n",
      "7453/7453 [==============================] - 4s 497us/step - loss: 0.1215 - accuracy: 0.9502\n",
      "Epoch 10/10\n",
      "7453/7453 [==============================] - 3s 436us/step - loss: 0.1115 - accuracy: 0.9564\n",
      "828/828 [==============================] - 6s 7ms/step\n",
      "Standardized: 91.58% (0.91%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "# load dataset\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dense_train_short\n",
    "Y = labels_train_short['NR.AhR']\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# baseline model\n",
    "def create_baseline():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=(801,), activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=10, batch_size=10)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('standardize', StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       " ('mlp', <keras.wrappers.scikit_learn.KerasClassifier at 0xb537209b0>)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=StandardScaler().fit_transform(dense_train_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=labels_train['NR.AhR'].dropna()\n",
    "train_x=dense_train.loc[train_y.index].drop(columns=['Unnamed: 0'])\n",
    "train_x=StandardScaler().fit_transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_y)\n",
    "encoded_train = encoder.transform(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=801))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8441/8441 [==============================] - 4s 466us/step - loss: 0.2762 - accuracy: 0.8980\n",
      "Epoch 2/10\n",
      "8441/8441 [==============================] - 2s 284us/step - loss: 0.2425 - accuracy: 0.9082\n",
      "Epoch 3/10\n",
      "8441/8441 [==============================] - 2s 272us/step - loss: 0.2294 - accuracy: 0.9175\n",
      "Epoch 4/10\n",
      "8441/8441 [==============================] - 2s 241us/step - loss: 0.2161 - accuracy: 0.9199\n",
      "Epoch 5/10\n",
      "8441/8441 [==============================] - 2s 246us/step - loss: 0.2027 - accuracy: 0.9237\n",
      "Epoch 6/10\n",
      "8441/8441 [==============================] - 2s 249us/step - loss: 0.1986 - accuracy: 0.9280\n",
      "Epoch 7/10\n",
      "8441/8441 [==============================] - 2s 246us/step - loss: 0.1872 - accuracy: 0.9320\n",
      "Epoch 8/10\n",
      "8441/8441 [==============================] - 2s 246us/step - loss: 0.1800 - accuracy: 0.9366\n",
      "Epoch 9/10\n",
      "8441/8441 [==============================] - 2s 243us/step - loss: 0.1738 - accuracy: 0.9385\n",
      "Epoch 10/10\n",
      "8441/8441 [==============================] - 2s 246us/step - loss: 0.1645 - accuracy: 0.9450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0xb589c4780>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, encoded_train, epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y=labels_test_short['NR.AhR'].dropna()\n",
    "test_x=dense_test.loc[test_y.index].drop(columns=['Unnamed: 0'])\n",
    "test_x=StandardScaler().fit_transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(test_y)\n",
    "encoded_test = encoder.transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 458us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16214884733802892, 0.9397163391113281]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x,encoded_test,batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
